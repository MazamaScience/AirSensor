---
title: "MVCAA Tutorial 6: Methow Vallely Smoke"
author: "Mazama Science"
date: "2021-03-26"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MVCAA Tutorial 5: Building a Local Archive}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 5)
```

## Introduction
This tutorial demostrates how to evaluate the functioning of PA sensors by applying 
some of the AirSensors fucntions explored in the previous turorials of this series.
In order to run the code in this tutorial you must have 
followed the instructions in Tutorial 5 and created a local multi-month archive 
of PurpleAir timeseries data. Target audiences include grad students, 
researchers and any member of the public concerned about air quality and 
comfortable working with R and RStudio.

Tutorials in this series include:

* [MVCAA Tutorial 1: Creating PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_1.html)
* [MVCAA Tutorial 2: Exploring PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_2.html)
* [MVCAA Tutorial 3: Creating Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_3.html)
* [MVCAA Tutorial 4: Exploring Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_4.html)
* [MVCAA Tutorial 5: Building a Local Archive](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_5.html)
* [MVCAA Tutorial 6: Methow Vallely Smoke](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_6.html)

## Goal
The overarching goal is to show how to evaluate if PA sensors functioned well
under extreme environmental conditions such us the high level of PM25 concentratons
in the air caused by the wildfires that scorched the Pacific Northwest and California during 
Fall 2020. In order to do so, we are going to do some data exploration and 
compare measurments from an FRM monitor and a PA sensor for the Methow Valley. 

## Intro
On September 6 and 7 two wildfires were ignited not far from the Methow Valley – 
Cold Springs and Pearl Hill, which burned over 410,000 acres throughout the month.
Additionally, at the beginning of September several wildfires exploded in the 
southern, central and northern Oregon, and a “super massive” plume was carried 
to Washington State by the southerly winds. Eventually the smoke settled in the 
valleys and basins of Washington and air pollution reached unhealthy levels 
across the state (https://wasmoke.blogspot.com/). September was definetely the 
smokiest month during the Fall season as shown in the timeseries plots below. 

## Data and Graphics 

```{r directory-setup, eval = TRUE, warning = FALSE, message = FALSE}
# libraries
library(AirSensor)
library(PWFSLSmoke)
library(AirMonitorPlots)
library(ggplot2)

# Use the tutorial default archiveDir unless it is already defined
if ( !exists("archiveDir") ) {
  archiveDir <- file.path("C:/Users/astri/Mirror/Mazamascience/Projects/AirSensor/Data2/MVCAA/")}

setArchiveBaseDir(archiveDir)

# Set your archive base directory and check that is correct
setArchiveBaseDir(archiveDir)
getArchiveBaseDir()

```

```{r fall-overview-sensors, eval = TRUE, warning = FALSE, message = FALSE}
# load September sensors' data 
all_sensors_fall <- 
  sensor_load(
    collection = "mvcaa", # collectionName defined by user 
    startdate = 20200901,
    enddate = 20201201,
    timezone = "America/Los_Angeles"
  )

# Plot all hourly values with daily averages
all_sensors_fall %>%
  AirMonitorPlots::ggplot_pm25Timeseries() + 
  ggplot2::ggtitle("Methow Valley PA Sensors -- Fall, 2020") +
  AirMonitorPlots::geom_pm25Points(shape = "square", alpha = .1) + 
  AirMonitorPlots::stat_dailyAQCategory(alpha = .5) + 
  ggplot2::scale_y_continuous(limits = c(0, 300)) +
  AirMonitorPlots::custom_aqiStackedBar(width = 0.01) 
```

```{r r fall-overview-monitors, eval = TRUE, warning = FALSE, message = FALSE}
# define longitude and latitude 
xlim <- c(-120.093, -120.284)
ylim <- c(48.313, 48.510)

# load September monitors' data 
mv_monitors_fall <- PWFSLSmoke::monitor_load(startdate = 20200901, enddate = 20201201) %>%
  monitor_subset(xlim = xlim, ylim = ylim)

# Plot all hourly values with daily averages
mv_monitors_fall %>%
  AirMonitorPlots::ggplot_pm25Timeseries() + 
  ggplot2::ggtitle("Methow Valley FRM monitors -- Fall, 2020") +
  AirMonitorPlots::geom_pm25Points(shape = "square", alpha = .1) + 
  AirMonitorPlots::stat_dailyAQCategory(alpha = .5) + 
  ggplot2::scale_y_continuous(limits = c(0, 300)) +
  AirMonitorPlots::custom_aqiStackedBar(width = 0.01)
```
Data from the FRM monitors and the PA sensors have similar trends.
Let's see more closely how Purple Air sensors performed compared to federal monitors
during September 2020.

```{r prep-monitor-data, eval = TRUE, warning = FALSE, message = FALSE}

# find federal monitors in the Methow Valley
# define longitude and latitude 
xlim <- c(-120.093, -120.284)
ylim <- c(48.313, 48.510)

# load Sep data
mv_monitors <- PWFSLSmoke::monitor_load(startdate = 20200901, enddate = 20201001) %>%
  monitor_subset(xlim = xlim, ylim = ylim)

# select only columns of interest for federal monitors 
names(mv_monitors$meta)
mv_monitors_meta <- as_tibble(mv_monitors$meta) %>%
  select(monitorID, siteName, longitude, latitude)

print(mv_monitors_meta$siteName) #"Winthrop-Chewuch Rd" "Twisp-Glover St" 

```

```{r prep-sensor-data, eval = TRUE, warning = FALSE, message = FALSE}
# load mvcaa pas file 
mvcaa <- get(load(file.path(archiveDir, "mvcaa.rda")))

# find sensors close to the monitor "Twisp-Glover St"
sensors <- pas_filterNear(pas = mvcaa, longitude = -120.1211, latitude = 48.3645, 
                          radius = "10 km")

print(sensors$label)

# select only meta data of interest for sensors
names(sensors)
sensors_meta <- as_tibble(sensors) %>%
  select(label, deviceDeploymentID, latitude, longitude)

# create sensor IDs object (must be as.character())
sensorIDs <- as.character(unique(sensors_meta$deviceDeploymentID))
print(sensorIDs) # 3 sensors 

# subset airsensor file for September using sensorIDs
sensors_subset <- 
  sensor_load(
    collection = "mvcaa",  
    startdate = 20200901,
    enddate = 20201001,
    timezone = "America/Los_Angeles") %>%
  monitor_subset(monitorIDs = sensorIDs)

# check if all 4 sensors are present
print(sensors_subset$meta$deviceDeploymentID)
# if we didn't have data for a sensor during September, 
# that sensor would not be present although it would appear in the $meta.
```

```{r dailyBarplot-Twisp-Glover, eval = TRUE, warning = FALSE, message = FALSE}
# create a dailyBarplot for the Twisp-Glover monitor
print(mv_monitors_meta) # find monitorID 

Twisp <- mv_monitors %>%
  monitor_subset(monitorIDs = "530470009_01")

monitor_dailyBarplot(
  Twisp,
  main = "Daily Average PM2.5 for Twisp -- Sep 2020",
  axes = TRUE)
addAQILegend(cex = 0.7)

```

```{r dailyBarplot-sensors, eval = TRUE, warning = FALSE, message = FALSE}
# create short name for dailyBarplot title 
sensors_subset$meta$shortName <-
  sensors_subset$meta$siteName %>%
  stringr::str_replace("MV Clean Air Ambassador @", "") %>%
  stringr::str_replace("MV Clean Air Ambassador-", "") %>%
  stringr::str_trim()

# create dailyBarplot for the 4 sensors 
layout(matrix(seq(4)))
opar <- par(mar = c(1,1,1,1))
on.exit(par(opar))
for (ID in sensorIDs) {
  siteName <- sensors_subset$meta[ID, 'shortName']
  monitor_dailyBarplot(
    sensors_subset,
    monitorID = ID,
    main = siteName,
    axes = TRUE
  )
  addAQILegend(cex = 0.7)
}
par(opar)
layout(1)
```
 
We can see that the Twisp monitor recorded increasing PM25
concentrations up to very unhealthy levels between ~ Sep 10 and 19. Three out of
four PA sensors within a radius of 10 km from the don't show data during the smokiest day.
The [QC algorithm AB_01](https://mazamascience.github.io/AirSensor/reference/PurpleAirQC_hourly_AB_01.html), that used into the function `pat_createAirSensor()` in
Tutorial 5, is invalidating many hourly values on those days presumably
because the A and B PM2.5 values differ by more than is allowed in AB_01.
We can demostrate this and fix the problem by creating a new airsensor object
for each sensor by applying the [QC algorithm AB_00](https://mazamascience.github.io/AirSensor/reference/PurpleAirQC_hourly_AB_00.html)
and replot the data.
Let's start exploring the raw data by running `pat_internalFit()` and
for a quick assessment.
We'll then compare each sensor performance against the Twisp monitor by fitting
a linear model (monitor ~ senosr) with the `pat_externalFit()` function.

*NOTE*: By looking at the meta data in the pat` objects, we can see that the currurent
nearest monitor is different from the monitor that collected PM25 concentrations
during September 2020. For this reason we are going to edit the metadata by replacing
the new `pwfsl_closestMonitorID` with the old one.

```{r pat-exploration, eval = TRUE, warning = FALSE, message = FALSE}
#--------------- pat internal fits----------------------------------------------
Balky_Hill <- pat_loadMonth(
  id = "ab5dca99422f2c0d_13669",
  datestamp = 202009,
  timezone = "America/Los_Angeles"
)
pat_internalFit(Balky_Hill)

Benson_Creek <- pat_loadMonth(
  id = "f6c44edd41c941c7_10182",
  datestamp = 202009,
  timezone = "America/Los_Angeles"
)
  
pat_internalFit(Benson_Creek)

Liberty_Bell <- pat_loadMonth(
  id = "db5d6b3b79f5830e_39237",
  datestamp = 202009,
  timezone = "America/Los_Angeles"
)

pat_internalFit(Liberty_Bell)


Beaver_Creek <- pat_loadMonth(
  id = "2e3b5ceea86a885b_10168",
  datestamp = 202009,
  timezone = "America/Los_Angeles"
)

pat_internalFit(Beaver_Creek)

#--------------- pat external fits----------------------------------------------
# First fix the closest monitor ID by substituting the current one with the Twisp
# monitor ID

# check the current nearest monitor 
Balky_Hill$meta$pwfsl_closestMonitorID #"840530470016_01"

# assign Twisp monitor ID to pwfsl_closestMonitorID 
Balky_Hill$meta$pwfsl_closestMonitorID <- "530470009_01"
Benson_Creek$meta$pwfsl_closestMonitorID <- "530470009_01"
Liberty_Bell$meta$pwfsl_closestMonitorID <- "530470009_01"
Beaver_Creek$meta$pwfsl_closestMonitorID <- "530470009_01"

# fit linear models
# Twisp ~ Balky_Hill
lm_BH <- pat_externalFit(
  pat = Balky_Hill,
  showPlot = TRUE
)

# Twisp ~ Benson_Creek
lm_BC <- pat_externalFit(
  pat = Benson_Creek,
  showPlot = TRUE
)

# Twisp ~ Liberty_Bell
lm_LB <- pat_externalFit(
  pat = Liberty_Bell,
  showPlot = TRUE
)
# distance: 4.2 km
# fit: 0.901 (missing days)

# Twisp ~ Beaver_Creek
lm_BeC <- pat_externalFit(
  pat = Beaver_Creek,
  showPlot = TRUE
)
```

The internal fit plots show that all sensors did quite a good job at measuring
the PM25 concentrations,
and that only the Benson Creek sensor had multiple days with missing data.
However, when compared to the monitor data (external fit), the plots show that Balky Hill was
the one performing best, followed by Liberty Bell High School, and Beaver Creek
(we are not considering Benson Creek due to the substantial missing data during the
smokiest days). Given the thousands of observations included in
each data set, we would expect external fits with an r-squared value ~ 0.99 and a slope ~ 1
for sensors that functioned very well. Lastly, it's interesting to observe that,
in the timeseries at the bottom of the graphic,
the all sensors tend to overestimate PM25 concentrations (slope < 1) when levels
get near and above 50 µg/m3.

Now let's create new sensor objects by applying the QC algorithm AB_00 and replot
the data.
```{r sensors-objects-AB00, eval = TRUE, warning = FALSE, message = FALSE}
#--- create sensors objects for all sensors using AB_00 ----
BH_00 <- 
  Balky_Hill %>%
  pat_createAirSensor(
    FUN = PurpleAirQC_hourly_AB_00
  )

BC_00 <- 
  Benson_Creek %>%
  pat_createAirSensor(
    FUN = PurpleAirQC_hourly_AB_00
  )

LB_00 <- 
  Liberty_Bell %>%
  pat_createAirSensor(
    FUN = PurpleAirQC_hourly_AB_00
  )

BeC_00 <- 
  Beaver_Creek %>%
  pat_createAirSensor(
    FUN = PurpleAirQC_hourly_AB_00
  )

# combine all sensors objects into a list of sensors 
sensorList <- c(BH_00, BC_00, LB_00, BeC_00)
class(sensorList)

sensorList <- list()
sensorList[[1]] <- BH_00
sensorList[[2]] <- BC_00
sensorList[[3]] <- LB_00
sensorList[[4]] <- BeC_00
sensors_subset_00 <- monitor_combine(sensorList)
```

```{r dailyBarplot-sensors-AB00, eval = TRUE, warning = FALSE, message = FALSE}
# create short name for the plot title 
sensors_subset_00$meta$shortName <-
  sensors_subset_00$meta$siteName %>%
  stringr::str_replace("MV Clean Air Ambassador @", "") %>%
  stringr::str_replace("MV Clean Air Ambassador-", "") %>%
  stringr::str_trim()


# create dailyBarplot for the 4 sensors 
layout(matrix(seq(4)))
opar <- par(mar = c(1,1,1,1))
on.exit(par(opar))
for (ID in sensorIDs) {
  siteName <- sensors_subset_00$meta[ID, 'shortName']
  monitor_dailyBarplot(
    sensors_subset_00,
    monitorID = ID,
    main = siteName,
    axes = TRUE
  )
  addAQILegend(cex = 0.7)
}
par(opar)
layout(1)
```
This plot demostrate that, initially, the sensors's data was invalidated by the 
QC algorithm AB_01 and that applying the QC algorithm AB_00 fixed the problem.
However, it's your call to decide which sensor to include in your study based on 
the overall sensor performance including internal and exernal fits. 

## Conclusion
