---
title: "MVCAA Tutorial 5: Building a Local Archive"
author: "Mazama Science"
date: "2021-03-16"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MVCAA Tutorial 5: Building a Local Archive}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 5)
```

## Introduction

This tutorial demonstrates how to create a multi-month archive of PurpleAir
timeseries data that can be loaded from a local `archiveDataDir`. Where 
Tutorial 1 demonstrated how to save and work with a small number of sensors
for a single month, this tutorial provides a more organized approach for working
with larger networks of sensors over extended periods of time. Target
audiences include grad students, researchers and any member of the public
concerned about air quality and comfortable working with R and RStudio.

Tutorials in this series include:

* [MVCAA Tutorial 1: Creating PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_1.html)
* [MVCAA Tutorial 2: Exploring PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_2.html)
* [MVCAA Tutorial 3: Creating Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_3.html)
* [MVCAA Tutorial 4: Exploring Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_4.html)
* [MVCAA Tutorial 5: Building a Local Archive](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_5.html)
* [MVCAA Tutorial 6: Methow Vallely Smoke](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_6.html)

## Goal

The goal in this tutorial is to explain the _well known_ file naming protocol
and directory structure required for data to be loaded using the `pat_load()`
and `sensor_load()` functions. We will build a multi-month archive for the 
Methow Valley and demonstrate accessing that data.

## Directory Structure

The *AirSensor* package has a variety of "load" functions, all of which assume
that pre-generated data files will be found in specific locations underneath
an archive directory. The base of this directory is specified by 
`setArchiveBaseUrl()` if the archive is web based or `setArchiveBaseDir()` if
the archive is local.

For a multi-year archive, the overall structure beneath the `BaseDir` will look 
something like this, depending on how many years of data you have:

```
├── airsensor
│   ├── 2020
│   ├── 2021
│   └── latest
├── pas
│   ├── 2020
│   └── 2021
├── pat
│   ├── 2019
│   │   ├── 01
│   │   ├── ...
│   │   └── 12
│   ├── 2020
│   │   ├── 01
│   │   ├── ...
│   │   └── 12
│   ├── 2021
│   │   ├── 01
│   │   ├── 02
│   │   └── 03
│   └── latest
```

### airsensor
* The directory must have the following structure: ~airsensor/year.

* File naming must be airsensor_scaqmd_YYYYMM.rda

* Example: ~airsensor_scaqmd_202009.rda

### pas
* The directory must have the following structure: ~pas/year.

* File naming must be pas_YYYYMMDD.rda

* Example: ~pas/2021/pas_20210317.rda

*NOTE*: we are using 2021 as an example since we'll be downloading the latest `pas`
data. For this local archive, the only purpuse of the `pas` data is to be used for 
extracting the device deoploymet IDs for the Methow Valley.

### pat
* The directory must have the following structure: ~pat/year/month.

* File naming must be pat_id_YYYYMM.rda

* Example: ~pat/2020/09/pat_ab5dca99422f2c0d_13669__202009.rda

*NOTE*: "ab5dca99422f2c0d_13669" corresponds to the device deployment ID, and each 
month directory will have individual `pat` files rather than a `patList` like the one we created in Tutorial 1. 

## _load() Functions
Unless a `BaseDir` for a local archive is specified using the function setArchiveBaseDir(), by default all `_load()` functions in the *AirSensor* package will load data from the `Baseurl` mantained by the package http://data.mazamascience.com/PurpleAir/v1/. 

Package functions that load pre-generated data files download data from this URL. 

These functions include:

pas_load()

pat_load()

pat_loadLatest()

pat_loadMonth()

sensor_load()

sensor_loadLatest()

sensor_loadMonth()

To avoid internet latency, specification of `BaseDir` will always take precedence over specification of `Baseurl`. For this reason, if you previously set a `BaseDir`
and you then want to load data from the `Baseurl` using the setArchiveBaseurl() 
function, you have to set `BaseDir` to 
NULL first (i.e. `setArchiveBaseDir(NULL)`).

(They are supposed to override any `baseUrl`
settingn but this needs to be tested.)_

## R script

The following R script will take several minutes to run and will create an
archive of 'pas', 'pat' and 'airsensor' data files on your computer. Once these 
files have been created, loading them will be very fast.

After running the script, a final 
section will demonstrate how to load and work with these local data files.

This R script can be used as a starting point for anyone interested in creating 
small collections of data for other communities and other dates.

_TODO: R script similar to tutorial 1 but using the "well known" structure._

*LEFT AT ROW 200!!*
```{r create-archive, eval = FALSE, warning = FALSE, message = FALSE}
# Methow Valley local data archive: Setup

# TODO similar to Tutorial 1

# ----- Setup ------------------------------------------------------------------
# Use the default archiveDir unless it is already defined
if ( !exists("archiveDir") ) {
  archiveDir <- file.path("~/Data/MVCAA")
}

# Create a ~pas/2021 directory
dir.create(file.path(archiveDir, "pas/2021"), recursive = TRUE)

# Create a pat/2020/MM directory underneath for September, October, and November
dir.create(file.path(archiveDir, "pat/2020/09"), recursive = TRUE)
dir.create(file.path(archiveDir, "pat/2020/10"), recursive = TRUE)
dir.create(file.path(archiveDir, "pat/2020/11"), recursive = TRUE)

# Create an airsensor/2020 directory 
dir.create(file.path(archiveDir, "airsensor/2020"), recursive = TRUE)

# Check the directories you just created 
list.dirs(archiveDir)

# AirSensor package
library(AirSensor)

# Set the archiveBaseUrl so we can get a 'pas' object
setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")

# ----- Create PAS object ------------------------------------------------------

# Create a 'pas' object limited to MVCAA sensors
#   - load most recent 'pas' for the entire country
#   - subset to include sensors labeled MVCAA
mvcaa <-
  pas_load() %>%
  pas_filter(stringr::str_detect(label, "MV Clean Air Ambassador"))
  # NOTE: Could have filtered by area with:
  #pas_filterArea(w = -120.5, e = -120.0, s = 48.0, n = 49.0)

# Look at it
pas_leaflet(mvcaa)

# Save it in our archive directory
save(mvcaa, file = paste0(archiveDir, "/pas/2021/pas_20210317.rda"))
list.files(file.path(archiveDir, "pas/2021"))

# Examine the pas directory:
list.files(file.path(archiveDir, "pas/2021"))
#### LEFT HERE###
# ----- Create PAT objects for September----------------------------------------

# Get all the deviceDeploymentIDs
mvcaa_ids <- pas_getDeviceDeploymentIDs(mvcaa)

# Specify times
startdate <- "2020-09-01"
enddate <- "2020-10-01"
timezone <- "America/Los_Angeles"

# Create an empty List to store things
patList <- list()

# Initialize counters
idCount <- length(mvcaa_ids)
count <- 0 
successCount <- 0

# Loop over all ids and get data (might take a while).
for (id in mvcaa_ids[1:idCount]) {
  
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # It's nice to copy-paste the full function signature so you can see all possible arguments
    patList[[id]] <- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = mvcaa,
      startdate = startdate,
      enddate = enddate,
      timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
  
}

# How many did we get?
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

# Save it in our archive directory
save(patList, file = file.path(archiveDir, "patList.rda"))

# ----- Evaluate patList -------------------------------------------------------

# We can use sapply() to apply a function to each element of the list
sapply(patList, function(x) { return(x$meta$label) })

# How big is patList in memory?
print(object.size(patList), units="MB")

# How big patList.rda on disk (as compressed binary) 
fileSize <- file.size(file.path(archiveDir, "patList.rda"))
sprintf("%.1f Mb", fileSize/1e6)
```

## Loading Local Data

Now we have a local archive of data that we can work with by running
`setArchiveBasedir()`.

```{r load-local-data, eval = TRUE, warning = FALSE, message = FALSE}
# TODO similar to Tutorial 1
# Empty current environment to ensure we're using our local archive.
# But retain "DATA_DIR if it has been set.
rm(list = setdiff(ls(), c("DATA_DIR")))

if ( exists("DATA_DIR") ) {
  archiveDir <- file.path(DATA_DIR)
} else {
  archiveDir <- file.path("~/Data/MVCAA")
}

# AirSensor package
library(AirSensor)

# Examine archive directory:
list.files(file.path(archiveDir))
 
# Load files
mvcaa <- get(load(file.path(archiveDir, "mvcaa.rda"))) 
patList <- get(load(file.path(archiveDir, "patList.rda")))

# Interactive map
pas_leaflet(mvcaa)

# Print site names and associated ids
sapply(patList, function(x) { return(x$meta$label) })

# Pull out Balky Hill as a separate 'pat' object
Balky_Hill <- patList[["ab5dca99422f2c0d_13669"]]

# Basic plot
pat_multiplot(Balky_Hill)
```

----

_Best of luck assessing air quality in your community!_
