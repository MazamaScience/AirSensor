---
title: "MVCAA Tutorial 5: Building a Local Archive"
author: "Mazama Science"
date: "2021-03-16"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{MVCAA Tutorial 5: Building a Local Archive}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width = 7, fig.height = 5)
```

## Introduction

This tutorial demonstrates how to create a multi-month archive of PurpleAir
timeseries data that can be loaded from a local `archiveDataDir`. Where 
Tutorial 1 demonstrated how to save and work with a small number of sensors
for a single month, this tutorial provides a more organized approach for working
with larger networks of sensors over extended periods of time. Target
audiences include grad students, researchers and any member of the public
concerned about air quality and comfortable working with R and RStudio.

Tutorials in this series include:

* [MVCAA Tutorial 1: Creating PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_1.html)
* [MVCAA Tutorial 2: Exploring PAT Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_2.html)
* [MVCAA Tutorial 3: Creating Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_3.html)
* [MVCAA Tutorial 4: Exploring Airsensor Data](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_4.html)
* [MVCAA Tutorial 5: Building a Local Archive](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_5.html)
* [MVCAA Tutorial 6: Methow Vallely Smoke](https://mazamascience.github.io/AirSensor/articles/articles/MVCAA_Tutorial_6.html)

## Goal

The goal in this tutorial is to explain the _well known_ file naming protocol
and directory structure required for data to be loaded using the `pat_load()`
and `sensor_load()` functions. We will build a multi-month archive for the 
Methow Valley and demonstrate accessing that data.

## Directory Structure

The *AirSensor* package has a variety of "load" functions, all of which assume
that pre-generated data files will be found in specific locations underneath
an archive directory. The base of this directory is specified by 
`setArchiveBaseUrl()` if the archive is web based or `setArchiveBaseDir()` if
the archive is local.

For a multi-year archive, the overall structure beneath the `BaseDir` will look 
something like this, depending on how many years of data you have:

```
├── airsensor
│   ├── 2020
│   ├── 2021
│   └── latest
├── pas
│   ├── 2020
│   └── 2021
├── pat
│   ├── 2019
│   │   ├── 01
│   │   ├── ...
│   │   └── 12
│   ├── 2020
│   │   ├── 01
│   │   ├── ...
│   │   └── 12
│   ├── 2021
│   │   ├── 01
│   │   ├── 02
│   │   └── 03
│   └── latest
```

### airsensor
* The directory must have the following structure: ~airsensor/year.

* File naming must be airsensor_scaqmd_YYYYMM.rda

* Example: ~airsensor_scaqmd_202009.rda

### pas
* The directory must have the following structure: ~pas/year.

* File naming must be pas_YYYYMMDD.rda

* Example: ~pas/2021/pas_20210317.rda

*NOTE*: we are using 2021 as an example since we'll be downloading the latest `pas`
data. For this local archive, the only purpuse of the `pas` data is to be used for 
extracting the device deoploymet IDs for the Methow Valley.

### pat
* The directory must have the following structure: ~pat/year/month.

* File naming must be pat_id_YYYYMM.rda

* Example: ~pat/2020/09/pat_ab5dca99422f2c0d_13669__202009.rda

*NOTE*: "ab5dca99422f2c0d_13669" corresponds to the device deployment ID, and each 
month directory will have individual `pat` files rather than a `patList` like the one we created in Tutorial 1. 

## _load() Functions
Unless a `BaseDir` for a local archive is specified using the function setArchiveBaseDir(), by default all `_load()` functions in the *AirSensor* package will load data from the `Baseurl` mantained by the package http://data.mazamascience.com/PurpleAir/v1/. 

Package functions that load pre-generated data files download data from this URL. 

These functions include:

pas_load()

pat_load()

pat_loadLatest()

pat_loadMonth()

sensor_load()

sensor_loadLatest()

sensor_loadMonth()

To avoid internet latency, specification of `BaseDir` will always take precedence over specification of `Baseurl`. For this reason, if you previously set a `BaseDir`
and you then want to load data from the `Baseurl` using the setArchiveBaseurl() 
function, you have to set `BaseDir` to 
NULL first (i.e. `setArchiveBaseDir(NULL)`).

(They are supposed to override any `baseUrl`
settingn but this needs to be tested.)_

## R script

The following R script will take several minutes to run and will create an
archive of 'pas', 'pat' and 'airsensor' data files on your computer. Once these 
files have been created, loading them will be very fast.

After running the script, a final 
section will demonstrate how to load and work with these local data files.

This R script can be used as a starting point for anyone interested in creating 
small collections of data for other communities and other dates.

_TODO: R script similar to tutorial 1 but using the "well known" structure._

*LEFT AT ROW 403!!*
```{r create-archive, eval = FALSE, warning = FALSE, message = FALSE}
# Methow Valley local data archive: Setup

# TODO similar to Tutorial 1

# ----- Setup ------------------------------------------------------------------
# Use the default archiveDir unless it is already defined
if ( exists("DATA_DIR") ) {
  archiveDir <- file.path(DATA_DIR)
} else {
  archiveDir <- file.path("~/Data/MVCAA")
}

# Create a ~pas/2021 directory. Edit the year beased on the date of the pas data 
# loading
dir.create(file.path(archiveDir, "pas/2021"), recursive = TRUE)

# Create a pat/2020/MM directory underneath for September, October, and November
dir.create(file.path(archiveDir, "pat/2020/09"), recursive = TRUE)
dir.create(file.path(archiveDir, "pat/2020/10"), recursive = TRUE)
dir.create(file.path(archiveDir, "pat/2020/11"), recursive = TRUE)

# Create an airsensor/2020 directory 
dir.create(file.path(archiveDir, "airsensor/2020"), recursive = TRUE)

# Check the directories you just created 
list.dirs(archiveDir)

# AirSensor package
library(AirSensor)

# Set the archiveBaseUrl so we can get a 'pas' object
setArchiveBaseDir(NULL)
getArchiveBaseDir()

setArchiveBaseUrl("http://data.mazamascience.com/PurpleAir/v1")

# ----- Create PAS object ------------------------------------------------------

# Create a 'pas' object limited to MVCAA sensors
#   - load most recent 'pas' for the entire country
#   - subset to include sensors labeled MVCAA
mvcaa <-
  pas_load() %>%
  pas_filter(stringr::str_detect(label, "MV Clean Air Ambassador"))
  # NOTE: Could have filtered by area with:
  #pas_filterArea(w = -120.5, e = -120.0, s = 48.0, n = 49.0)

# Look at it
pas_leaflet(mvcaa)

# Save it in our archive directory.
# Change the the year of the directory and the date in pas_YYYYMMDD based on the
# date of the pas data loading 
save(mvcaa, file = paste0(archiveDir, "/pas/2021/pas_20210317.rda"))
list.files(file.path(archiveDir, "pas/2021"))

# Examine the pas directory:
list.files(file.path(archiveDir, "pas/2021"))

# ----- Create PAT objects for September----------------------------------------

# Get all the deviceDeploymentIDs
mvcaa_ids <- pas_getDeviceDeploymentIDs(mvcaa)

# Specify times
startdate <- "2020-09-01"
enddate <- "2020-10-01"
timezone <- "America/Los_Angeles"

# # Create pat files for September 2020
# for (id in mvcaa_ids){
#   filename = paste0(archiveDir,"pat/2020/09", "/", id, ".rda")
#   pat = pat_createNew(id = id,
#                       pas = mvcaa,
#                       startdate = startdate, 
#                       enddate = enddate)
#   save(pat, file = filename)
# }

# Initialize counters
idCount <- length(mvcaa_ids)
count <- 0 
successCount <- 0

# Loop over all ids and get data (might take a while).
for (id in mvcaa_ids[1:idCount]) {
  
  filename = paste0(archiveDir,"/pat/2020/09/", "pat_", id, "_202009", ".rda") 
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # It's nice to copy-paste the full function signature so you can see all possible arguments
    pat<- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = mvcaa,
      startdate = startdate,
      enddate = enddate,
      timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    save(pat, file = filename)  #Save each pat file in ~ pat/2020/09
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
}

# How many did we get?
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))


# ----- Create PAT objects for October -----------------------------------------

# Specify times
startdate <- "2020-10-01"
enddate <- "2020-11-01"
timezone <- "America/Los_Angeles"

# Initialize counters
idCount <- length(mvcaa_ids)
count <- 0 
successCount <- 0

# Loop over all ids and get data (might take a while).
for (id in mvcaa_ids[1:idCount]) {
  
  filename = paste0(archiveDir,"/pat/2020/10/", "pat_", id, "_202010", ".rda")
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # It's nice to copy-paste the full function signature so you can see all possible arguments
    pat<- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = mvcaa,
      startdate = startdate,
      enddate = enddate,
      timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    save(pat, file = filename)  #Save each pat file in ~ pat/2020/09
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
}

# How many did we get?
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

# ----- Create PAT objects for November ----------------------------------------

# Specify times
startdate <- "2020-11-01"
enddate <- "2020-12-01"
timezone <- "America/Los_Angeles"

# Initialize counters
idCount <- length(mvcaa_ids)
count <- 0 
successCount <- 0

# Loop over all ids and get data (might take a while).
for (id in mvcaa_ids[1:idCount]) {
  
  filename = paste0(archiveDir,"/pat/2020/11/", "pat_", id, "_202011", ".rda")
  count <- count + 1
  print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
  
  # Use a try-block in case you get "no data" errors
  result <- try({
    
    # It's nice to copy-paste the full function signature so you can see all possible arguments
    pat<- pat_createNew(
      id = id,
      label = NULL,        # not needed if you have the id
      pas = mvcaa,
      startdate = startdate,
      enddate = enddate,
      timezone = timezone,
      baseUrl = "https://api.thingspeak.com/channels/",
      verbose = FALSE
    )
    successCount <- successCount + 1
    save(pat, file = filename)  #Save each pat file in ~ pat/2020/09
    
  }, silent = FALSE)
  
  if ( "try-error" %in% class(result) ) {
    print(geterrmessage())
  }
}

# How many did we get?
print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))

# ----- Evaluate each month directory under ~ pat/2020 -------------------------
list.files(file.path(archiveDir, "pat/2020/09"))
list.files(file.path(archiveDir, "pat/2020/10"))
list.files(file.path(archiveDir, "pat/2020/11"))

# ----- Create airsensor objects for September ---------------------------------
# Initialize counters
idCount <- length(patList)
count <- 0
successCount <- 0

# # Loop over ids and create 'airsensor' objects (might take a while).
# for ( id in names(patList) ) {
# 
#   count <- count + 1
#   print(sprintf("Working on %s (%d/%d) ...", id, count, idCount))
#   
#   # Use a try-block in case you get "no data" errors
#   result <- try({
#     
#     # It's nice to copy-paste the full function signature so you can see all possible arguments
#     airsensorList[[id]] <- pat_createAirSensor(
#       pat = patList[[id]],
#       parameter <- "pm25",
#       FUN = PurpleAirQC_hourly_AB_01
#     )
#     successCount <- successCount + 1
#     
#   }, silent = FALSE)
#   
#   if ( "try-error" %in% class(result) ) {
#     print(geterrmessage())
#   }
#   
# }
# 
# # How many did we get?
# print(sprintf("Successfully created %d/%d pat objects.", successCount, idCount))
# 
# # Save it in our archive directory
# save(airsensorList, file = file.path(archiveDir, "airsensorList.rda"))

# WIP
# from JOn: First you have to create individual sensor objects, one for each pat. 
# Then use PWFSLSmoke::combine() to combine them into a single sensor object.

# load files 
list.files(archiveDir)
patList <- get(load(file.path(archiveDir, "patList.rda")))
airList <- get(load(file.path(archiveDir, "airsensorList.rda")))
save(airList, file = file.path(archiveDir, "airsensor/2020/airsensor_scaqmd_202009.rda"))

startdate <- "2020-09-01"
enddate <- "2020-10-01"

getArchiveBaseDir() #OK

# try to load the airlist 
test <- sensor_load(
  collection = "scaqmd",
  startdate = startdate,
  enddate = enddate,
  days = 7,
  timezone = "America/Los_Angeles"
)
# Error in sensor_filterDatetime(., startdate = startdate, enddate = enddate,  : 
#   Parameter 'sensor' is not a valid 'airsensor' object.


test <- pat_createAirSensor(
      pat = ,
      parameter <- "pm25",
      FUN = PurpleAirQC_hourly_AB_01
    )



# ----- Create airsensor objects for October -----------------------------------

# ----- Create airsensor objects for November ----------------------------------

```

## Loading Local Data

Now we have a local archive of data created by following the _well known_ 
directory structure that we can work with by running
`setArchiveBaseDir()`.

```{r load-local-data, eval = TRUE, warning = FALSE, message = FALSE}
# TODO similar to Tutorial 1
# Empty current environment to ensure we're using our local archive.
# But retain "DATA_DIR if it has been set.
rm(list = setdiff(ls(), c("DATA_DIR")))

if ( exists("DATA_DIR") ) {
  archiveDir <- file.path(DATA_DIR)
} else {
  archiveDir <- file.path("~/Data/MVCAA")
}

setArchiveBaseDir(archiveDir)

# Set your archive base directory and check that is correct
setArchiveBaseDir(archiveDir)
getArchiveBaseDir()

# Load the pas file
mvcaa <- pas_load(datestamp = 20210317) 

# Use the interactive map to quickly get the "deviceDeploymentID" of the sensors
# you want to explore further based on their location. 
pas_leaflet(mvcaa)

# However, data for a specific sensor could not be available for a given month,
# so you should make sure to have the pat file in your month directory as well.
list.files(file.path(archiveDir, "pat/2020/09"))
list.files(file.path(archiveDir, "pat/2020/10"))
list.files(file.path(archiveDir, "pat/2020/11"))

# Load the September pat data for Little Cougar 
Little_Cougar  <- 
  pat_load(id = "96b108298883ca47_64441",
           pas = mvcaa, 
           startdate = 20200901,
           enddate = 20200930, 
           timezone = "America/Los_Angeles")

# Load the fall pat data for Little Cougar by loading all 3 months of data 
Little_Cougar_fall  <- 
  pat_load(id = "96b108298883ca47_64441",
           pas = mvcaa, 
           startdate = 20200901,
           enddate = 20201201, 
           timezone = "America/Los_Angeles")

# Explore the data 
LC_fall_data <- Little_Cougar_fall$data

# Basic plot for Little_Cougar 
pat_multiplot(Little_Cougar_fall)
```

----

_Best of luck assessing air quality in your community!_
